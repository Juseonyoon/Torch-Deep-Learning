{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'width': 1800, 'height': 768, 'scroll': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1800,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qtkGyAsoVwDi",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>본 자료는 Deep Learning 수업 이규빈 교수님의 강의자료를 기반으로하여 juseonyoon이 내용을 이해하기 편하도록 추가하거나 편집한 내용임.\n",
    "\n",
    "본 편에서는 직접코드를 제작하여 학습에대한 내용을 이해하는 것과 deep learning framework 에서 제공하는 패키지를 사용하여 딥러닝을 구현한다. \n",
    "\n",
    "</p></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QMF49K1W0v0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Linear Regression\n",
    "---\n",
    "\n",
    "\n",
    "> ![대체 텍스트](https://iaml.it/blog/fun-with-pytorch-part-1/images/regressione_lineare_1.png)\n",
    "\n",
    "\n",
    "- We are going to implement linear regression in three ways\n",
    "- **Manul Gradient Style** - Implement Gradient Descent Algorithm without Auto Gradient\n",
    "- **Auto Gradient Style** - Implement Gradient Descent Algorithm with Auto Gradient\n",
    "- **Pytorch Style** - Implement Linear Regression and Descent Algorithm with Pytorch Style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bn_8We7Fkhq7",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1.1. Linear Regression - Manual Gradient Style\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PNavS7qxkpoK",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's import required python package\n",
    "\n",
    "Here, python package random is used for initialize the weight ($w$) with random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LHm90UiP_rly",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9C2DDBiQ_r7P",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Define the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Z9sIl80uzta",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x2739ebedd48>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "zip(x_data, y_data) #[(1.0,2.0),(2.0,4.0),(3.0,6.0)] 세트로 묶어주는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-2t0wgxaxBQV",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then, initialize the weight ($w$) with any random number you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "LVZBTY_vxU9X",
    "outputId": "ec6ff606-23b2-4d60-abce-e86c79f6359d",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w is initialized with 0.4187019650000422\n",
      "0.4187019650000422\n"
     ]
    }
   ],
   "source": [
    "w = random.random()\n",
    "print('w is initialized with {}'.format(w)) #{}안에 원하는 숫자 집어 넣는법\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9CPsEEvozbma",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Define the forward function that represents the linear regression model ($\\hat y=x*w$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5xALiXpz11j",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return x * w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKXjEjK_z6pU",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Define $Loss(w)$ which is the squared error between $\\hat y$ and $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AZ531lQC0fAb",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hY2CkVQB1AzU",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Define the $\\dfrac{\\partial Loss(w)}{\\partial w}=2*x*(x*w-y)$ which is for computing the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vwv9Cd9e3DmS",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def gradient(x, y):\n",
    "    return 2 * x * (x * w - y) #단순 미분형태를 수식으로 만들어 return 받는다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rY9dtHiB5nPX",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Check the predicted value ($\\hat y$) before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9002397125680375\n"
     ]
    }
   ],
   "source": [
    "print(forward(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "aQ54LnIG5txS",
    "outputId": "fed6e56c-10b2-42f1-99ea-504138c528b7",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of forward(4) (before training): 3.9002397125680375\n"
     ]
    }
   ],
   "source": [
    "print('Prediction of forward(4) (before training): {}'.format(forward(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h1xIu6aY62n7",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Training loop\n",
    "\n",
    "```epoch``` & ```iteration``` & ```batch(= mini-batch)``` 의 의미    \n",
    "\n",
    "```epoch```전체 데이터 셋에 대해 한 번의 학습 과정이 완료됐다고 단편적으로 이해하셔도 모델을 학습 시키는 데는 무리가 없습니다.  \n",
    "```batch size```는 한 번의 batch마다 주는 데이터 샘플의 size. 여기서 batch(보통 mini-batch라고 표현)는 나눠진 데이터 셋을 뜻하며 ```iteration```는 epoch를 나누어서 실행하는 횟수라고 생각하면 됨.  \n",
    "\n",
    "메모리의 한계와 속도 저하 때문에 대부분의 경우에는 한 번의 epoch에서 모든 데이터를 한꺼번에 집어넣을 수는 없습니다. 그래서 데이터를 나누어서 주게 되는데 이때 몇 번 나누어서 주는가를 iteration, 각 iteration마다 주는 데이터 사이즈를 batch size라고 합니다.\n",
    "\n",
    ">![이해](https://mblogthumb-phinf.pstatic.net/MjAxOTAxMjNfMjU4/MDAxNTQ4MjM1Nzg3NTA2.UtvnGsckZhLHOPPOBWH841IWsZFzNcgwZvYKi2nxImEg.CdtqIxOjWeBo4eNBD2pXu5uwYGa3ZVUr8WZvtldArtYg.PNG.qbxlvnf11/20190123_182720.png?type=w800)\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "이미지가 100개(```1 epoch```) 있을때 20개씩(```batch(= batch-size, = mini-batch)```) 잘라서 총 5번(```iteration```)을 하겠다. \n",
    "<br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x0000025210526808>\n"
     ]
    }
   ],
   "source": [
    "print(zip(x_data, y_data)) #[(1.0,2.0),(2.0,4.0),(3.0,6.0)] 세트로 묶어주는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "dAwVbBHu67XW",
    "outputId": "0b04acd8-d0e1-4034-d54e-0b8ed20c5937",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad: -0.02, (x, y) = (1.0, 2.0)\n",
      "\tgrad: -0.09, (x, y) = (2.0, 4.0)\n",
      "\tgrad: -0.18, (x, y) = (3.0, 6.0)\n",
      "Progress: 0 epoch, w: 1.99, loss: 0.0\n",
      "\tgrad: -0.02, (x, y) = (1.0, 2.0)\n",
      "\tgrad: -0.06, (x, y) = (2.0, 4.0)\n",
      "\tgrad: -0.13, (x, y) = (3.0, 6.0)\n",
      "Progress: 1 epoch, w: 1.99, loss: 0.0\n",
      "\tgrad: -0.01, (x, y) = (1.0, 2.0)\n",
      "\tgrad: -0.05, (x, y) = (2.0, 4.0)\n",
      "\tgrad: -0.1, (x, y) = (3.0, 6.0)\n",
      "Progress: 2 epoch, w: 2.0, loss: 0.0\n",
      "\tgrad: -0.01, (x, y) = (1.0, 2.0)\n",
      "\tgrad: -0.03, (x, y) = (2.0, 4.0)\n",
      "\tgrad: -0.07, (x, y) = (3.0, 6.0)\n",
      "Progress: 3 epoch, w: 2.0, loss: 0.0\n",
      "\tgrad: -0.01, (x, y) = (1.0, 2.0)\n",
      "\tgrad: -0.03, (x, y) = (2.0, 4.0)\n",
      "\tgrad: -0.05, (x, y) = (3.0, 6.0)\n",
      "Progress: 4 epoch, w: 2.0, loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5): #전체 데이터 셋을 총 5번 돌리겠다. \n",
    "    # Dataset iteration\n",
    "    for x_val, y_val in zip(x_data, y_data): # Dataset iteration zip은 y=xw+b에서 한세트씩 내부의 값들을 불러오는듯함. \n",
    "        grad = gradient(x_val, y_val) # Compute gradient(위에서 만든 미분함수 임, 식에 대입해서 값을 가져옴)\n",
    "        w = w - 0.01 * grad # Update weight\n",
    "        print('\\tgrad: {}, (x, y) = ({}, {})'.format(round(grad, 2), x_val, y_val))\n",
    "        loss_out = loss(x_val, y_val) # Compute loss\n",
    "    \n",
    "    # Monitoring the training result\n",
    "    print('Progress: {} epoch, w: {}, loss: {}'\n",
    "          .format(epoch, round(w,2), round(loss_out, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghzCcHmm8ix9"
   },
   "source": [
    "Check the predicted value ($\\hat y$) after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "RHCpMo_Y8o2E",
    "outputId": "fb4ee06a-c4cb-4cb4-9d89-63a0e71916bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of forward(4) (after training): 7.990243061383346\n"
     ]
    }
   ],
   "source": [
    "print('Prediction of forward(4) (after training): {}'.format(forward(4)))\n",
    "#위에서 before predict의 경우 random w를 사용하기 때문에 학습하기 전에는 prediction이 정답과 다른 것을 볼 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k79tUJBN_XwW"
   },
   "source": [
    "## 1.2. Linear Regression - Auto Gradient Style\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iIsWkDpXkx0s"
   },
   "source": [
    "Let's import required python package\n",
    "\n",
    "In the previous exp lecture, we learned that the ``torch.autograd`` package provides automatic differentiation for PyTorch Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pq67Hd_gG152"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDsG-n9tKjqh"
   },
   "source": [
    "Define the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGrJqgheKkMF"
   },
   "outputs": [],
   "source": [
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "#input output이 1:1로 matching 됌 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XoxGCm1HLb-k"
   },
   "source": [
    "Then, initialize the weight ($w$) with random number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "S45XLI6UKrAX",
    "outputId": "2443cdf1-5abf-4aab-fd75-0c5ce5654156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w is initialized with -0.10125605016946793\n"
     ]
    }
   ],
   "source": [
    "w = Variable(torch.randn(1), requires_grad=True) #vector tensor를 제작한다. track이 가능하도록 true로 설정한다. \n",
    "print('w is initialized with {}'.format(w.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IGX5cAZHioeX"
   },
   "source": [
    "**Note**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "a2xMHhuwioqy",
    "outputId": "689cfa94-0c3c-4175-b55f-6597e83aab23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w              : tensor([-0.1013], requires_grad=True)\n",
      "w.data         : tensor([-0.1013])\n",
      "w.data[0]      : -0.10125605016946793\n",
      "w.requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "print('w              : {}'.format(w))\n",
    "print('w.data         : {}'.format(w.data))\n",
    "print('w.data[0]      : {}'.format(w.data[0]))\n",
    "print('w.requires_grad: {}'.format(w.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_uYM3RekNFO-"
   },
   "source": [
    "Define the forward function that represents the linear regression model (y^=x∗w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m-dJ0aDfNJto"
   },
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    return x * w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9g8kHboNNMw7"
   },
   "source": [
    "Define $Loss(w)$ which is the squared error between $\\hat y$ and $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g5hy9NU0NQyG"
   },
   "outputs": [],
   "source": [
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred - y) * (y_pred - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "766gwaEZgmdJ"
   },
   "source": [
    "**Note**\n",
    "\n",
    "The difference between **Manual Gradient Style** and **Auto Gradient Style** is that you don't have to define ``gradient`` function because the gradient is automatically calculated by the ``backward()`` method\n",
    "\n",
    "When $ Loss(w) = (y_{pred} - y)^2$\n",
    "\n",
    "Define the $\\dfrac{\\partial Loss(w)}{\\partial w}=2*x*(x*w-y)$ which is for computing the gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MlT1cumUiDUg"
   },
   "source": [
    "Check the predicted value ($\\hat y$) before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "SuLNVzhliCNq",
    "outputId": "3ebef9da-b4c2-4496-83db-3e15b7833a4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of forward(4) (before training): -0.4050242006778717\n"
     ]
    }
   ],
   "source": [
    "print('Prediction of forward(4) (before training): {}'.format(forward(4).data[0])) #before training이기 때문에 개판임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l349bx2_kWLT"
   },
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "qMYLtXx0krw7",
    "outputId": "53b3cf0d-bb95-4aa8-d769-0b4a15983df5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad: -4.202512264251709, (x, y) = (1.0, 2.0)\n",
      "\tgrad: -16.473848342895508, (x, y) = (2.0, 4.0)\n",
      "\tgrad: -34.10086441040039, (x, y) = (3.0, 6.0)\n",
      "Progress: 0, w: 0.4465161859989166, loss: 32.30191421508789, predict : 1.7860647439956665\n",
      "\tgrad: -3.1069676876068115, (x, y) = (1.0, 2.0)\n",
      "\tgrad: -12.179313659667969, (x, y) = (2.0, 4.0)\n",
      "\tgrad: -25.211179733276367, (x, y) = (3.0, 6.0)\n",
      "Progress: 1, w: 0.8514907956123352, loss: 17.655654907226562, predict : 3.405963182449341\n",
      "\tgrad: -2.297018527984619, (x, y) = (1.0, 2.0)\n",
      "\tgrad: -9.004312515258789, (x, y) = (2.0, 4.0)\n",
      "\tgrad: -18.638927459716797, (x, y) = (3.0, 6.0)\n",
      "Progress: 2, w: 1.1508934497833252, loss: 9.65026569366455, predict : 4.603573799133301\n",
      "\tgrad: -1.6982131004333496, (x, y) = (1.0, 2.0)\n",
      "\tgrad: -6.65699577331543, (x, y) = (2.0, 4.0)\n",
      "\tgrad: -13.779982566833496, (x, y) = (3.0, 6.0)\n",
      "Progress: 3, w: 1.3722453117370605, loss: 5.274664402008057, predict : 5.488981246948242\n",
      "\tgrad: -1.255509376525879, (x, y) = (1.0, 2.0)\n",
      "\tgrad: -4.921596527099609, (x, y) = (2.0, 4.0)\n",
      "\tgrad: -10.187705039978027, (x, y) = (3.0, 6.0)\n",
      "Progress: 4, w: 1.535893440246582, loss: 2.8830370903015137, predict : 6.143573760986328\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    for x_val, y_val in zip(x_data, y_data): # Dataset iteration\n",
    "        loss_out = loss(x_val, y_val) # Compute loss\n",
    "        loss_out.backward() # Compute gradient backward 방식을 사용하면 자동으로 w가 갱신되어 구해짐. \n",
    "        print('\\tgrad: {}, (x, y) = ({}, {})'.format(w.grad.data[0], x_val, y_val))\n",
    "        w.data = w.data - 0.01 * w.grad.data # Update weight\n",
    "        \n",
    "        # Manually zero the gradients after updating weights\n",
    "        w.grad.data.zero_()\n",
    "    \n",
    "    # Monitoring the traing result\n",
    "    print('Progress: {}, w: {}, loss: {}, predict : {}'\n",
    "          .format(epoch, w.data[0], loss_out.data[0],forward(4).data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eOuKhUnjCuwO"
   },
   "source": [
    "Check the predicted value ($\\hat y$) after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "b8AmxoZUCu8d",
    "outputId": "6c9fbdcb-1d81-4498-c979-8a0afdcd0e6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of forward(4) (after training): 7.999998569488525\n"
     ]
    }
   ],
   "source": [
    "print('Prediction of forward(4) (after training): {}'.format(forward(4).data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ohaQp_wqrJfs"
   },
   "source": [
    "## 1.3. Linear Regression - Pytorch Style\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAWm0QAtk7x6"
   },
   "source": [
    "Let's import required python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "prd_tT3NrOYk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#여기서는 torch.nn 인풋 안했음 왜냐면 클래스를 직접 아래에 만들었기 때문임. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j0da9HZarW3X"
   },
   "source": [
    "PyTorch model takes inputs as the form of ``torch.Tensor`` wrapped with ``Variable()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VSFEnBE_rW9s"
   },
   "outputs": [],
   "source": [
    "x_data = Variable(torch.Tensor([[1.0], [2.0], [3.0]]))\n",
    "y_data = Variable(torch.Tensor([[2.0], [4.0], [6.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0lJAxpK_raTK"
   },
   "source": [
    "Define the linear regression model with the name of ``Model()``\n",
    "\n",
    "**Note that**\n",
    "\n",
    "- **All PyTorch neural network class must inherit** ``torch.nn.Module`` **class**\n",
    "- **In the** ``def __init__(self)`` **(constructor),** ``super(ClassName, self).__init__()`` **method should be included**\n",
    "- **All PyTorch neural netowrk class must include** ``forward()`` **method**\n",
    "- Ref. https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html\n",
    "- Ref. http://schoolofweb.net/blog/posts/%ED%8C%8C%EC%9D%B4%EC%8D%AC-oop-part-5-%EC%83%81%EC%86%8D%EA%B3%BC-%EC%84%9C%EB%B8%8C-%ED%81%B4%EB%9E%98%EC%8A%A4inheritance-and-subclass/\n",
    "\n",
    "\n",
    "**Usage of Linear Module**\n",
    "\n",
    "- ``torch.nn.Linear(in_features, out_features, bias=True)``\n",
    "-  ``in_features``  : size of input sample\n",
    "- ``out_features`` : size of output sample\n",
    "- ``bias`` : If set to False, the layer will not learn an additive bias (Default : ``True``)\n",
    "    - In the case of  ``bias=True``, the equation is $y=x*w+b$\n",
    "    - In the case of ``bias=False``, the equation is  $y=x*w$\n",
    "- Ref. https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LxzcSodNraZs"
   },
   "outputs": [],
   "source": [
    "# 토치 모듈임. linear & forward 해줌\n",
    "# import torch를 사용해야 만들수 있는 클래스임. \n",
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1, bias=False)  # One in and one out, bias = False, 아무것도 안적으면 default는 True임\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fDLkdlvur1TN"
   },
   "source": [
    "Declare the linear regression model\n",
    "\n",
    "You can check the number of weights (parameters) in model is 1\n",
    "\n",
    "You can print the structure of the model by using simple code ``print(model)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "TmKAO__arzvB",
    "outputId": "40c74b20-4fb5-4c00-961b-13867a19127e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1\n",
      "w is initialized with -0.9125654697418213\n",
      "Model(\n",
      "  (linear): Linear(in_features=1, out_features=1, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "print('Number of parameters: {}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))#무슨 파라메터인가?\n",
    "print('w is initialized with {}'.format(model.linear.weight.data[0][0]))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Q1ebPOhr9JQ"
   },
   "source": [
    "Define the ``criterion`` (Loss) with the ``torch.nn.MSELoss()`` (Mean Square Error)\n",
    "\n",
    "Define the ``optimizer`` with ``torch.optim.SGD()`` (Stochastic Gradient Descent) which is a kind of Gradient Descent Algorithm\n",
    "- It takes two inputs ``model.parameters()`` and ``lr``\n",
    "- ``model.parameters()`` refers to the learnable parameters of model\n",
    "- ``lr`` refers to the learning rate ($\\alpha$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ncf4gtZVuX95"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nk69Nxt1uaRS"
   },
   "source": [
    "Traning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9450
    },
    "colab_type": "code",
    "id": "-lmCxRfjub2l",
    "outputId": "07d9f58d-31d1-4fff-cebc-99234b317a66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.16646753251552582, w: 1.8909562826156616\n",
      "Epoch: 1, Loss: 0.08629684150218964, w: 1.9214885234832764\n",
      "Epoch: 2, Loss: 0.04473618045449257, w: 1.9434717893600464\n",
      "Epoch: 3, Loss: 0.023191191256046295, w: 1.9592996835708618\n",
      "Epoch: 4, Loss: 0.012022318318486214, w: 1.9706957340240479\n",
      "Epoch: 5, Loss: 0.006232402753084898, w: 1.9789009094238281\n",
      "Epoch: 6, Loss: 0.003230887232348323, w: 1.9848086833953857\n",
      "Epoch: 7, Loss: 0.0016748630441725254, w: 1.9890623092651367\n",
      "Epoch: 8, Loss: 0.0008682431071065366, w: 1.9921249151229858\n",
      "Epoch: 9, Loss: 0.0004500958020798862, w: 1.9943299293518066\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_data)#Model class 내의 forward\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y_data) #loss 수식\n",
    "    print('Epoch: {}, Loss: {}, w: {}'.format(epoch, loss.data.numpy(), model.linear.weight.data[0][0]))\n",
    "    #torch tensor를 numpy로 변환 (import 안해도 torch 내에 함수가 존재하는 듯 )\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OjEvCWx8CI0_"
   },
   "source": [
    "Check the predicted value ($\\hat y$) after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "wE66GVKfCWp1",
    "outputId": "bfaca866-260f-4726-facf-9b0801905cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.]])\n",
      "Prediction of model(hour_var) (after training): 7.983670234680176\n"
     ]
    }
   ],
   "source": [
    "hour_var = Variable(torch.Tensor([[4.0]])) # input값을 모델에 넣기 위해 model이 인식할 수 있는 변수(Variable)로 변환\n",
    "y_pred = model(hour_var) # Forward pass, weiguh와 loss는 학습된 상태임. \n",
    "print(hour_var)\n",
    "print('Prediction of model(hour_var) (after training): {}'.format(model(hour_var).data[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LTYLaoIAsFwn"
   },
   "source": [
    "# 2. XOR Problem\n",
    "![대체 텍스트](http://www.birc.co.kr/wp-content/uploads/2018/01/xor-768x414.png)\n",
    "\n",
    "- OR problem and AND problem can be solved by using Linear Model\n",
    "\n",
    "- How about XOR Problem? Let's solve XOR Problem in three different ways\n",
    "\n",
    "    - **Linear Model**\n",
    "    \n",
    "    - **Multilayer Perceptron without Nonlinear Activate Function**\n",
    "    \n",
    "    - **Multilayer Perceptron with Nonlinear Activate Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QZc1zlU2BcbT"
   },
   "source": [
    "## 2.1. XOR Problem - Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NSJ3Jc9kCjRc"
   },
   "source": [
    "Let's import required python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bA3lEbqx1sGu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable #OUPUT을 추출하기 위한 input변수를 만들기위해 Variable import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jhDBRguhDsVy"
   },
   "source": [
    "Define XOR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "qqOPMKC21VOd",
    "outputId": "8f415737-ffa7-4633-a98c-822f061400f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of x_data: torch.Size([4, 2])\n",
      "Size of y_data: torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "x_data = Variable(torch.Tensor([\n",
    "    [0, 0], # [x1, x2] pair\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "]))\n",
    "print('Size of x_data: {}'.format(x_data.size()))\n",
    "\n",
    "y_data = Variable(torch.Tensor([\n",
    "    [0], # [y]\n",
    "    [1],\n",
    "    [1],\n",
    "    [0]\n",
    "]))\n",
    "print('Size of y_data: {}'.format(y_data.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QB1_hdcjI_hO"
   },
   "source": [
    "Define **simple linear model** that takes two inputs\n",
    "\n",
    "$\\hat y = W_1 \\times x_1 + W_2 \\times x_2 + b_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0XxRQul5It4B"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(2, 1) # input이 두개임. 아무것도 안적으면 default는 bias= True임\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5S6FB_VfJpaM"
   },
   "source": [
    "Declare the **model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "LS_X0vy-Jp-f",
    "outputId": "53922007-509a-4ff9-d9a6-da686e6ad207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 3\n",
      "<bound method Module.parameters of Model(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")>\n",
      "Model(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "print('Number of parameters: {}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))#여기은 왜 parameter가 3인가?\n",
    "\n",
    "print(model.parameters)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJAlFSw2J6hc"
   },
   "source": [
    "Define the **criterion** and the **optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jorr6P7fKEC1"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ignmnQiTKh-M"
   },
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "bqpLje_kKhZx",
    "outputId": "4a97765e-f3b8-457e-d2f3-58e23deb7767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.4609106481075287, w1:0.01575891301035881, w2:-0.14183315634727478\n",
      "Epoch: 1, Loss: 0.4481443464756012, w1:0.02021685056388378, w2:-0.1365872621536255\n",
      "Epoch: 2, Loss: 0.436175137758255, w1:0.02451324462890625, w2:-0.13150684535503387\n",
      "Epoch: 3, Loss: 0.42495301365852356, w1:0.028653323650360107, w2:-0.1265866607427597\n",
      "Epoch: 4, Loss: 0.4144311845302582, w1:0.032642148435115814, w2:-0.12182163447141647\n",
      "Epoch: 5, Loss: 0.4045657813549042, w1:0.03648461773991585, w2:-0.11720684915781021\n",
      "Epoch: 6, Loss: 0.39531558752059937, w1:0.04018547385931015, w2:-0.11273753643035889\n",
      "Epoch: 7, Loss: 0.38664212822914124, w1:0.043749310076236725, w2:-0.108409084379673\n",
      "Epoch: 8, Loss: 0.3785092234611511, w1:0.04718057066202164, w2:-0.104217030107975\n",
      "Epoch: 9, Loss: 0.3708829879760742, w1:0.05048355832695961, w2:-0.10015705227851868\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_data)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print('Epoch: {}, Loss: {}, w1:{}, w2:{}'.format(epoch, loss.data, model.linear.weight.data[0][0],model.linear.weight.data[0][1]))\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDtMd4Y5Ktrv"
   },
   "source": [
    "Print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "-QjE2QM4Kz3l",
    "outputId": "feff528d-aba2-4049-9943-3a66c36ca1f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1\tx2\tTrue\tPred\n",
      "0.0\t0.0\t0.0\t0.0\n",
      "0.0\t1.0\t1.0\t0.0\n",
      "1.0\t0.0\t1.0\t0.0\n",
      "1.0\t1.0\t0.0\t0.0\n"
     ]
    }
   ],
   "source": [
    "print('x1\\tx2\\tTrue\\tPred')\n",
    "for i in range(len(y_data)):\n",
    "    print('{}\\t{}\\t{}\\t{}'\n",
    "          .format(x_data[i][0], x_data[i][1], y_data[i][0], torch.round(model(x_data))[i].data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hb9AswiINwE8"
   },
   "source": [
    "**XOR problem cannot be solved with linear model**\n",
    "\n",
    "How about Multilayer Perceptron?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9vva1_sTOsKA"
   },
   "source": [
    "## 2.2. XOR Problem - Multilayer Perceptron without Nonlinear Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2sRkt29OSeOp"
   },
   "source": [
    "Define **2-layer perceptron model** that takes two inputs\n",
    "\n",
    "By adding ``input_dim`` and ``hidden_dim`` argument, you can control the input dimension and the hidden dimension\n",
    "\n",
    "By using ``linearity`` which is boolean variable, you can add nonlinearity to the multilayer perceptron model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G2YHtGZT10mB"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, linearity=True):\n",
    "        super(Model, self).__init__()\n",
    "        self.linearity = linearity\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, 1)\n",
    "        if not linearity:\n",
    "            self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        if not self.linearity:\n",
    "            x = self.relu(x)\n",
    "        x_out = self.linear2(x)\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YerwqxBKkpv_"
   },
   "source": [
    "Declare the **model** with linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "UudqmMia2NU7",
    "outputId": "55429805-8df2-4f30-d001-b5fc9da7a0af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 13\n",
      "Model(\n",
      "  (linear1): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (linear2): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model(2, 3, linearity=True)\n",
    "print('Number of parameters: {}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-PK-dTtVk2-Y"
   },
   "source": [
    "Define the **criterion** and the **optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LJbSw24W2G7B"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6a4ipiLk6Mm"
   },
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "C6WIGqTM2OAt",
    "outputId": "d09fbef4-33d4-49b5-ef8f-0721a8c02428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.2318483591079712\n",
      "Epoch: 50, Loss: 0.2694298028945923\n",
      "Epoch: 100, Loss: 0.2565663754940033\n",
      "Epoch: 150, Loss: 0.2539123594760895\n",
      "Epoch: 200, Loss: 0.2523638606071472\n",
      "Epoch: 250, Loss: 0.25143709778785706\n",
      "Epoch: 300, Loss: 0.25087863206863403\n",
      "Epoch: 350, Loss: 0.25054001808166504\n",
      "Epoch: 400, Loss: 0.25033360719680786\n",
      "Epoch: 450, Loss: 0.2502070367336273\n",
      "Epoch: 500, Loss: 0.2501290440559387\n",
      "Epoch: 550, Loss: 0.25008073449134827\n",
      "Epoch: 600, Loss: 0.25005072355270386\n",
      "Epoch: 650, Loss: 0.2500319480895996\n",
      "Epoch: 700, Loss: 0.25002017617225647\n",
      "Epoch: 750, Loss: 0.2500127851963043\n",
      "Epoch: 800, Loss: 0.25000810623168945\n",
      "Epoch: 850, Loss: 0.25000515580177307\n",
      "Epoch: 900, Loss: 0.25000327825546265\n",
      "Epoch: 950, Loss: 0.25000208616256714\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_data)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    if epoch % 50 == 0:\n",
    "        print('Epoch: {}, Loss: {}'.format(epoch, loss.data))\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "55lzHrgWk-rU"
   },
   "source": [
    "Print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "C-7hMNSp98aG",
    "outputId": "eb673deb-3770-421b-a516-9a291cbc01bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1\tx2\tTrue\tPred\n",
      "0.0\t0.0\t0.0\t0.0\n",
      "0.0\t1.0\t1.0\t0.0\n",
      "1.0\t0.0\t1.0\t1.0\n",
      "1.0\t1.0\t0.0\t1.0\n"
     ]
    }
   ],
   "source": [
    "print('x1\\tx2\\tTrue\\tPred')\n",
    "for i in range(len(y_data)):\n",
    "    print('{}\\t{}\\t{}\\t{}'\n",
    "          .format(x_data[i][0], x_data[i][1], y_data[i][0], torch.round(model(x_data))[i].data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gecOiNJZlSpy"
   },
   "source": [
    "**XOR problem cannot be solved with Linear Multilayer Perceptron**\n",
    "\n",
    "**How about adding nonlinearity using the activation function **``nn.ReLU()``**?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hldolSzclxi2"
   },
   "source": [
    "## 2.3. XOR Problem - Multilayer Perceptron with Nonlinear Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gA7O1kBam38z"
   },
   "source": [
    "Declare the **model** with nonlinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "colab_type": "code",
    "id": "C59gSfHLm24F",
    "outputId": "42a9fd60-b94c-4cb7-8b7b-af3f4a47e9f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 13\n",
      "Model(\n",
      "  (linear1): Linear(in_features=2, out_features=3, bias=True)\n",
      "  (linear2): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model(2, 3, linearity=False)\n",
    "print('Number of parameters: {}'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QdM0yb5anjiL"
   },
   "source": [
    "Define the **criterion** and the **optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sg4gohVknmvH"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDYyOShDnpOi"
   },
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "-vSVuhPGnopc",
    "outputId": "46fcff84-a5b4-4a1b-f53d-bc749c3ce307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.1250005066394806\n",
      "Epoch: 50, Loss: 0.12500034272670746\n",
      "Epoch: 100, Loss: 0.1250002235174179\n",
      "Epoch: 150, Loss: 0.12500014901161194\n",
      "Epoch: 200, Loss: 0.12500010430812836\n",
      "Epoch: 250, Loss: 0.12500005960464478\n",
      "Epoch: 300, Loss: 0.12500004470348358\n",
      "Epoch: 350, Loss: 0.1250000298023224\n",
      "Epoch: 400, Loss: 0.1250000149011612\n",
      "Epoch: 450, Loss: 0.1250000149011612\n",
      "Epoch: 500, Loss: 0.1250000149011612\n",
      "Epoch: 550, Loss: 0.125\n",
      "Epoch: 600, Loss: 0.125\n",
      "Epoch: 650, Loss: 0.125\n",
      "Epoch: 700, Loss: 0.125\n",
      "Epoch: 750, Loss: 0.125\n",
      "Epoch: 800, Loss: 0.125\n",
      "Epoch: 850, Loss: 0.125\n",
      "Epoch: 900, Loss: 0.125\n",
      "Epoch: 950, Loss: 0.125\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x_data)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    if epoch % 50 == 0:\n",
    "        print('Epoch: {}, Loss: {}'.format(epoch, loss.data))\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NDvpCZGnny-N"
   },
   "source": [
    "Print the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "NOtreg3EnzeM",
    "outputId": "d2c1271c-59ba-48f5-fcf7-1dc83b4f9915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1\tx2\tTrue\tPred\n",
      "0.0\t0.0\t0.0\t0.0\n",
      "0.0\t1.0\t1.0\t1.0\n",
      "1.0\t0.0\t1.0\t1.0\n",
      "1.0\t1.0\t0.0\t0.0\n"
     ]
    }
   ],
   "source": [
    "print('x1\\tx2\\tTrue\\tPred')\n",
    "for i in range(len(y_data)):\n",
    "    print('{}\\t{}\\t{}\\t{}'\n",
    "          .format(x_data[i][0], x_data[i][1], y_data[i][0], torch.round(model(x_data))[i].data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vj_pjgjhoAmS"
   },
   "source": [
    "**XOR problem is solved by adding nonlinearity!**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [
    "qtkGyAsoVwDi",
    "bn_8We7Fkhq7",
    "k79tUJBN_XwW"
   ],
   "name": "(Exp) 03_Pytorch_Basics.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "juseonyoon_base1",
   "language": "python",
   "name": "juseonyoon_base1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
